{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG for *Foreign Trade and Export Control*\n",
    "\n",
    "This readme provides a concise overview of Foreign Trade and Export Control, integrating elements of Retrieval Augmented Generation (RAG) for enhanced information retrieval and response generation, with data sourced from BAFA (Bundesamt für Wirtschaft und Ausfuhrkontrolle).\n",
    "\n",
    "\n",
    "\n",
    "## Export Control Basics\n",
    "Export Control entails regulations governing the export of goods, software, and technology from Germany, with a focus on national security and economic interests, as defined by BAFA.\n",
    "\n",
    "## Key Inquiries and Questions\n",
    "\n",
    "Professionals in export control commonly address the following:\n",
    "\n",
    "Relevant Inquiries:\n",
    "* Export Regulations: Understanding guidelines and frameworks.\n",
    "* Compliance: Ensuring adherence to established rules.\n",
    "\n",
    "### RAG Integration\n",
    "Utilizing Retrieval Augmented Generation enhances the information retrieval and response generation processes for a more dynamic and contextually informed experience.\n",
    "\n",
    "\n",
    "### User-Specific Queries\n",
    "\n",
    "**For a Robotics Company:**\n",
    "*Question:* \"What BAFA regulations apply to exporting AI-powered robotic systems to Russia, and are there recent updates affecting our industry?\"\n",
    "\n",
    "**For a Medical Device Company:**\n",
    "*Question:* \"What documentation and compliance measures does BAFA require for exporting medical imaging devices to Russia, given the sensitivity of medical technology?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.1.0)\n",
      "Collecting langchain_openai (from -r requirements.txt (line 2))\n",
      "  Downloading langchain_openai-0.0.2.post1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.9 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (0.0.12)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (0.1.10)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (0.0.80)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (2.5.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from langchain->-r requirements.txt (line 1)) (8.2.3)\n",
      "Collecting openai<2.0.0,>=1.6.1 (from langchain_openai->-r requirements.txt (line 2))\n",
      "  Downloading openai-1.7.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting tiktoken<0.6.0,>=0.5.2 (from langchain_openai->-r requirements.txt (line 2))\n",
      "  Using cached tiktoken-0.5.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 1)) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain->-r requirements.txt (line 1)) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.7->langchain->-r requirements.txt (line 1)) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.7->langchain->-r requirements.txt (line 1)) (23.2)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.6.1->langchain_openai->-r requirements.txt (line 2))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.6.1->langchain_openai->-r requirements.txt (line 2))\n",
      "  Using cached httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: sniffio in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from openai<2.0.0,>=1.6.1->langchain_openai->-r requirements.txt (line 2)) (1.3.0)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.6.1->langchain_openai->-r requirements.txt (line 2))\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from openai<2.0.0,>=1.6.1->langchain_openai->-r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 1)) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (2023.11.17)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<0.6.0,>=0.5.2->langchain_openai->-r requirements.txt (line 2))\n",
      "  Using cached regex-2023.12.25-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai->-r requirements.txt (line 2))\n",
      "  Using cached httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai->-r requirements.txt (line 2))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ingrid/anaconda3/envs/export_rag/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 1)) (1.0.0)\n",
      "Downloading langchain_openai-0.0.2.post1-py3-none-any.whl (28 kB)\n",
      "Downloading openai-1.7.2-py3-none-any.whl (212 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tiktoken-0.5.2-cp311-cp311-macosx_11_0_arm64.whl (953 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "Using cached regex-2023.12.25-cp311-cp311-macosx_11_0_arm64.whl (291 kB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, h11, distro, tiktoken, httpcore, httpx, openai, langchain_openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 langchain_openai-0.0.2.post1 openai-1.7.2 regex-2023.12.25 tiktoken-0.5.2 tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a virtual environment\n",
    "\n",
    "```\n",
    "conda create -n export_rag python=3.11\n",
    "\n",
    "conda activate export_rag\n",
    "\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Environmental Variables\n",
    "In order for the embeddings to work, you'll need to create an account with HuggingFace, get an API key, and your key to your environmental variables.\n",
    "\n",
    "```\n",
    "export HF_API_KEY=YOUR_API_KEY\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain.llms import Ollama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, HTMLHeaderTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate \n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LLM and Embedding Model\n",
    "I'll use LM Studio to serve the LLM via the local inference server, and the embedding model will be served via the HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(base_url=\"http://localhost:1234/v1\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_API_KEY = os.environ.get(\"HF_API_KEY\")\n",
    "\n",
    "hf_embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=HF_API_KEY, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
    ")\n",
    "\n",
    "# set huggingface embeddings \n",
    "embedding = hf_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Data Source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_export_regulations = \"https://eur-lex.europa.eu/legal-content/DE/TXT/HTML/?uri=CELEX:02014R0833-20231001&qid=1704642681092\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF with country metadata\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "export_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
